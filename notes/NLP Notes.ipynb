{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad8f9a2",
   "metadata": {},
   "source": [
    "# NLP Notes\n",
    "\n",
    "## Experience at Principal\n",
    "\n",
    "**Project 1: question direction system**\n",
    "\n",
    "I worked on a team with two economists, two strategist, and had access to Bond and Stock experts.  Principal had 5,000 financial advisors can email the team with questions.  Led the creation of an NLP email classification system, that forwarded the email economist, strategist, Bond or Stock expert. They recently acquired the Wells Fargo network so the number of FA's 4X.\n",
    "\n",
    "The system was written using python: \n",
    "1. Data cleaning - some manual (such as wells vs principal), removed punctuation, stop words, lemmatization.\n",
    "2. Used TD-IFD (sklearn.feature_extraction.text.TfidfVectorizer), almost all of the emails would have some similar jargon, such as \"market\", this also had better results than bag of words, bag of words (n-gram), and a word2vec.\n",
    "3. Trained using pipelines with statification, mostly balanced dataset. GridsearchCV... KNN, Naive Bayes, but picked RandomForest. \n",
    "4. Note: in this case False Positive/Negative had the same result (sent to wrong person), so confusion matrix was not helpful.\n",
    "\n",
    "Libraries: scikit-learn, Gensim, Spacy \n",
    "\n",
    "\n",
    "**Project 2: sentiment ratio score**\n",
    "\n",
    "Investor sentiment index - it is commonly thought that small investor sentiment is a good signal for regime change (bull to bear market, etc).  Data came from another team:\n",
    "\n",
    "1. Sampled tweets / stock twits / a few blogs -> small investor bucket\n",
    "2. Text from market experts -> institutional investor bucket\n",
    "\n",
    "Goal was a ratio (small sentiment)/(large sentiment).\n",
    "\n",
    "Started with a dictionary approach with labeling positive/negative word ratio for each.  Ended with a TD-IFD and Logistic/Ridge regression, for each.  Saving the top words for each category for word clouds and time series.\n",
    "    \n",
    "\n",
    "Libraries: scikit-learn, Gensim, Spacy \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Jargon\n",
    "\n",
    "- Corpus - all of the docs.\n",
    "- Document - the text you are using for analysis.\n",
    "- Vocabulary - all of the tokens from your corpus.\n",
    "- Semantic - are meanings of sentences.\n",
    "- Syntactic - rules for the creation of sentences.\n",
    "\n",
    "Preprocessing: \n",
    "\n",
    "- Regular Expressions\n",
    "- Stemming (NLTK) - preprocessing step to take off prefix and/or suffix.\n",
    "- Lemmatization - preprocessing step that looks up the base word for each token.  (can add new lemmas)\n",
    "- Stop words - common words that don't add much meaning to the sentence.\n",
    "\n",
    "Token information:\n",
    "\n",
    "- PoS - Part of speech (noun, verb)\n",
    "- NER - Named entity recognition\n",
    "\n",
    "Word Embeddings / Vecor space model:\n",
    "\n",
    "- One Hot Encoding - dummy variables for words.\n",
    "- Bag or words - counts from sentences/documents from your vocabulary.\n",
    "- Bag of ngrams - counts from sentences/documents (1,2) means single words and two consecutive words.\n",
    "- TF-IDF - log(Total # of Documents / # of DOCUMENTS the term appears in), so if it apears in all documents log(4/4), in one document log(4/1).  Higher means more fidelity.\n",
    "\n",
    "Encoded: \n",
    "\n",
    "- AutoEncoder - a compressed form representation of words, such as word2vec, an unsupervised learning algorithm creates the Neural Network hidden nodes and represents it with a vector.\n",
    "- Word2Vec - Self-supervised autoencoder using either a continuous bag of words or a skip-gram to train the neural net.  The word2vec vector is the perceptron values. \n",
    "\n",
    "\n",
    "Visualize Embeddings:\n",
    "- (PCA or SVD) - plot to see if there is a seperation between first two components.\n",
    "\n",
    "Classification algo:\n",
    "\n",
    "- KNN\n",
    "- Naive Bayes\n",
    "- Logistic regression (for binomial choice)\n",
    "- Random forrest classifier (ensemble)\n",
    "\n",
    "- CV - Cross validation with n-folds.\n",
    "- GridSearchCV - Cross validation with k parameters and n-folds.\n",
    "\n",
    "Evaluation:\n",
    "- Look at top words for sanity check.\n",
    "    - Lime - For Word2Vec the most influential words are not obvious, Lime perturbs the document and the most influential towards each classification.\n",
    "- Confusion Matrix - counts of: predicted vs true.\n",
    "- Accuracy - percentage of how correct you are overall\n",
    "- Precision - true posititives / (all actual positives) - Precision is a good measure to determine, when the costs of False Positive is high. For instance, email spam detection. In email spam detection, a false positive means that an email that is non-spam (actual negative) has been identified as spam (predicted spam). The email user might lose important emails if the precision is not high for the spam detection model.\n",
    "- Recall -  true positives / (all predicted positives) - Applying the same understanding, we know that Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.  For instance, in fraud detection or sick patient detection. If a fraudulent transaction (Actual Positive) is predicted as non-fraudulent (Predicted Negative), the consequence can be very bad for the bank.\n",
    "- F1 - F1 Score might be a better measure to use if we need to seek a balance between Precision and Recall AND there is an uneven class distribution (large number of Actual Negatives).\n",
    "\n",
    "Random:\n",
    "- Imbalanced data - more of one classificatoin than another, use under-sampling, over-sampling.\n",
    "\n",
    "I haven't used:\n",
    "\n",
    "- CNN - convolutional neural network\n",
    "- RNN - Recurrent neural network\n",
    "- LSTM - Long short-term memory\n",
    "- Bert - bidirectional encoder representation from transformers\n",
    "- Transformers - sequence to sequence task.\n",
    "- LSA - Latent Semantic Analysis - analyzing docs to find the underlying meaning or concepts in the doc. Uses SVD to reduce features.\n",
    "\n",
    " \n",
    "## Python Libraries and Tools\n",
    "\n",
    "Pandas\n",
    "\n",
    "Numpy\n",
    "\n",
    "Scikit-learn:\n",
    "- train_test_split\n",
    "- Pipeline\n",
    "- classification_report\n",
    "- TfidfVectorizer\n",
    "- KNeighborsClassifier\n",
    "- confusion_matrix\n",
    "- naive_bayes.MultinomialNB\n",
    "- RandomForestClassifier\n",
    "- CountVectorizer\n",
    "- PCA, TruncatedSVD\n",
    "- LogisticRegression\n",
    "\n",
    "Spacy\n",
    "- nlp (trains pipelines)\n",
    "- \n",
    "\n",
    "NLTK\n",
    "- Stemming\n",
    "\n",
    "GENSIM\n",
    "- Word2Vec\n",
    "\n",
    "keras \n",
    "- preprocessing.text\n",
    "- to_categorical\n",
    "\n",
    "re\n",
    "\n",
    "Lime\n",
    "- LimeTextExplainer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3b2d6",
   "metadata": {},
   "source": [
    "https://www.interviewbit.com/nlp-interview-questions/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
